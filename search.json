[
  {
    "objectID": "posts/lists_mutability_cloning.html",
    "href": "posts/lists_mutability_cloning.html",
    "title": "Lists, Mutability and Cloning",
    "section": "",
    "text": "Let’s talk about the most important principles of lists and other mutable objects. I also want to mention some common “gotchas”.\nTo be open, this description is based on how I understand the topic. In some aspects it differs from what can be found on the internet. I don’t know why, but I think most descriptions of a variable on the internet are either incomplete or incorrect. This is how I understand that and what helps me understand lists, mutability and cloning."
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#variables-vs.-pointers-vs.-objects",
    "href": "posts/lists_mutability_cloning.html#variables-vs.-pointers-vs.-objects",
    "title": "Lists, Mutability and Cloning",
    "section": "Variables vs. Pointers vs. Objects",
    "text": "Variables vs. Pointers vs. Objects\nThis is foundational to understand the whole mutability and cloning thing. As far as I know, variables (or names), pointers (or references) and objects are three completely different things. - Variables live in a namespace. A namespace is a mapping (we can think of it as a dict) from variables to pointers. So a variable is basically a label of a pointer. - Pointers point to a location in memory. I think of them as memory addreses. - An object is the actual thing on location in memory.\nSo, to sum this up, variables map to pointers and pointers map to objects. It is common to think that “variables are just names for objects”. Also, I found on the internet the sentences “variables are names associated with concrete objects” or “variable is essentially a name that is assigned to a value”. No, that’s incorrect. A variable is a name (in a namespace) of a pointer. And that pointer points to a location in memory where an object can be found. That object has then a value (along with a type and an identity). But a namespace isn’t the only place we can found pointers."
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#lists-only-contain-pointers",
    "href": "posts/lists_mutability_cloning.html#lists-only-contain-pointers",
    "title": "Lists, Mutability and Cloning",
    "section": "Lists Only Contain Pointers",
    "text": "Lists Only Contain Pointers\nOnce we understand the differences between varaibles, pointers and objects, now comes the most important part: lists only contain pointers. Not objects. Not variables. Pointers. A list is internally basically an array, where each item in the array is a pointer to a memory location.\nThe pointer, as an element of a list, can be created either implicitely, or explicitely. If we type L = ['a'], this is what I call an implicit creation of a pointer. Internally, two new objects are created at two different memory locations: The string 'a' and a new list. A pointer to the string 'a' is placed as the first element of the new list. And a pointer to the new list is placed in the current namespace and is assigned the label L.\nOr, we can place a pointer as an element of a list explicitely. That would look like this:\nA = 'a'\nL = [A]\nFirst, a new object (the string 'a') is created in memory and its pointer is placed to the current namespace with the label A. Second, a new list is created, its first element is the pointer that is named A and a pointer to this new list is placed to the namespace under the name L."
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#mutation",
    "href": "posts/lists_mutability_cloning.html#mutation",
    "title": "Lists, Mutability and Cloning",
    "section": "Mutation",
    "text": "Mutation\nMutation is the ability of some python objects (types of objects) to change. Numbers, strings or tuples are examples of immutable types. Once objects of these types are created, they cannot be changed. Any pointers that point to such objects will always point to the same unchanged objects.\nExamples of mutable types are lists, dictionaries or sets. After they are created, they can be changed (extended, shortened, changed elements etc.). If multiple pointers point to such an object, the change made via one pointer is visible via all other pointers:\n\nL1 = []\nL2 = [L1, 'abc']\nL1.append(1)\nprint(L2)\n\n[[1], 'abc']\n\n\nIn this example, the list L2 has two pointers to it: One is the variable L1 and the other is the first element of the list L2. Both places, the varaible and the first element of L2, contain the same memory address - the one where L1 is located. A change made using the variable L1 is visible through L2."
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#self-referencing",
    "href": "posts/lists_mutability_cloning.html#self-referencing",
    "title": "Lists, Mutability and Cloning",
    "section": "Self-Referencing",
    "text": "Self-Referencing\nI learned this only after many years of using Python and it blew my mind. Lists contain pointers, ok. But there are not limitations on those pointers. In particular, nothing prevents a list to cointain a pointer to itself:\n\nL1 = ['abc']\nL1.append(L1)\nprint(L1)\n\n['abc', [...]]\n\n\nIn this example, the second element of the list L1 is a pointer that points to memory location where the list L1 is located. The interactive python shell has a particular way of letting you know this once you try to print that list: It prints the string ‘[…]’ as the second element of the list, where the pointer to itself is. Surprisingly, one can normally iterate over that list:\n\nfor i in L1:\n    print(i)\n\nabc\n['abc', [...]]"
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#common-gotchas",
    "href": "posts/lists_mutability_cloning.html#common-gotchas",
    "title": "Lists, Mutability and Cloning",
    "section": "Common Gotchas",
    "text": "Common Gotchas\nThere are two gotchas I want to mention here, both from my favorite textbook “Introduction to Computation and Programming Using Python” (I have to manage the references in some more methodical way than just typing the whole long name each time…), pages 98 and 99.\n\n1) The repetition operator *\n\nL1 = [[]]*2\nL2 = [[], []]\nfor i in range(len(L1)):\n    L1[i].append(i)\n    L2[i].append(i)\nprint(f'{L1 = }, {L2 = }')\n\nL1 = [[0, 1], [0, 1]], L2 = [[0], [1]]\n\n\nHere, the repetition operator creates a sequence where the very same object is repeated n times. In this example, L1 is a list of two pointers that are the same (they both point to the same empty list). Whereas the list L2 is made of two different pointers (each is pointing to a different empty list).\n\n\n2) Default values\n\ndef append_val(val, list_1 = []):\n    list_1.append(val)\n    print(list_1)\n\nappend_val(3)\nappend_val(4)\n\n[3]\n[3, 4]\n\n\nThe objects to be used as default values are created at a function definition time. And a pointer to this one object is bound to list_1 each time the function is called without the second parameter.\nWe can test the “default value is created at a function definition time” claim like this. The string 'here!' is not printed until the function append_val is defined. And that function is not defined until the default value of param2 is created and that value is not created until the function long_computation finishes creating it.\n\ndef long_computation():\n    x = 0\n    for i in range(int(1e10)):\n        x += 0\n\ndef append_val(val, list_1 = [], param2 = long_computation()):\n    list_1.append(val)\n\nprint('here!')"
  },
  {
    "objectID": "posts/lists_mutability_cloning.html#cloning",
    "href": "posts/lists_mutability_cloning.html#cloning",
    "title": "Lists, Mutability and Cloning",
    "section": "Cloning",
    "text": "Cloning\nI’m not sure about the exact terminology here. Does “cloning” refer to only shallow copy or both shallow and deep copy? Anyway, I will try to explicitely state what kind of copy I mean each time.\n\nImmutable Types\nAs a preface, I think we only talk about “copying” in connection with mutable types. But here I think it is interesting to look at this behavior of immutable types:\n\nprint(id('abc'))\nprint(id('abc'))\nprint('-------')\nprint(id(2))\nprint(id(2))\nprint('-------')\nprint(id(True))\nprint(id(True))\nprint('-------')\nprint(id(None))\nprint(id(None))\nprint('-------')\nprint(id(range(10)))\nprint(id(range(10)))\nprint('-------')\nprint(id(3.14))\nprint(id(3.14))\nprint('-------')\nprint(id((2,)))\nprint(id((2,)))\n\n1640577203152\n1640577203152\n-------\n140710899286984\n140710899286984\n-------\n140710898401712\n140710898401712\n-------\n140710898401776\n140710898401776\n-------\n1640673096160\n1640673096160\n-------\n1640673251568\n1638533141008\n-------\n1640676037040\n1640674705520\n\n\nI’m not 100% sure if I can generalize like this, but I will :). 1) All instances of str, int, bool and NoneType and range types that have the same value are the same object. 2) Instances of float and tuple types, even if they have the same value, are different objects.\nBUT, this surprisingly yields True:\n\nprint(id((2,)) == id((2,)))\n\nTrue\n\n\nI guess it means that the same tuples created in a single expression are the same object, but tuples created in different expressions are different objects… But I honestly don’t know.\nSimilarly, two float instances that actually represent the same integer are the same object when created in a single expression, but different object when created individually:\n\nprint(id(float(2)))\nprint(id(float(2)))\nprint(id(float(2)) == id(float(2)))\n\n1640673251568\n1640673251440\nTrue\n\n\nAnyway, back to cloning. Of mutable types. There are two basic versions of cloning, a shallow copy and a deep copy. Again, the examples here are from my already mentioned favorite textbook, pages 101 and 102.\n\n\nShallow Copy\nRecall that a list is just an array of pointers. A shallow copy is simply a new list (a new object) that contains the same pointers.\nA shallow copy of a list L can be obtained by: - slicing (L[:]) - using the list method copy (L.copy()) - using list comprehension ([e for e in L]) - using the list constructor (list(L)) - or using the generic copy method of the copy module (copy.copy(L)).\nRemember, it would be just a copy of the pointers. If objects that those pointers point at are mutable, any changes made to the objects via the old list are visible in the new list.\n\nL = [2]\nL1 = [L]\nL2 = L1[:]\nL.append(3)\nprint(f'{L1 = }, {L2 = }')\n\nL1 = [[2, 3]], L2 = [[2, 3]]\n\n\n\n\nDeep Copy\nIf we have a list whose elements are mutable, we might want to copy the list in such a way that changes via the old list do not propagate to the new list - in other words, we might want not only to copy the list, but also its elements. This is what the function deepcopy of the module copy does:\n\nimport copy\n\n\nL = [2]\nL1 = [L]\nL2 = copy.deepcopy(L1)\nL.append(3)\nprint(f'{L1 = }, {L2 = }')\n\nL1 = [[2, 3]], L2 = [[2]]\n\n\nHere, L2 is not affected by the mutation of L, because L2 doesn’t contain anymore the object to which L points. It contains its copy. I’m not sure about the exact internal mechanics, but I imagine the deepcopy function does this: It goes to L1 and makes a shallow copy of it. It then goes to each element in that new list, copies the object to which the element points (creates new such object at a different memory location) and replaces the pointer in the new list with a pointer to this new object. It does that “all the way to the bottom”, meaning if an element of the list being copied is another list, its deep copy is also created:\n\nL = [2]\nL1 = [[L]]\nL2 = copy.deepcopy(L1)\nL.append(3)\nprint(f'{L1 = }, {L2 = }')\n\nL1 = [[[2, 3]]], L2 = [[[2]]]\n\n\nThere are two subtleties to be mentioned here. First, if the list to be copied is self-referencing, the deepcopy function somehow notices it and replicates the structure in the new list. Second, if two elements of the old list contain the same pointer, the object this pointer points to is copied only once and the new pointer is used twice in the new list. In other words, also this structure is maintained.\n\nL1 = ['abc']\nL1.append(L1)\nprint(L1, id(L1), id(L1[-1]))\nL2 = copy.deepcopy(L1)\nprint(L2, id(L2), id(L2[-1]))\n\n['abc', [...]] 1640674902656 1640674902656\n['abc', [...]] 1640674911232 1640674911232\n\n\n\nL = ['abc']\nL1 = [L, L]\nL2 = copy.deepcopy(L1)\nL2[0].append(2)\nprint(L2)\n\n[['abc', 2], ['abc', 2]]"
  },
  {
    "objectID": "posts/finger_exercises.html",
    "href": "posts/finger_exercises.html",
    "title": "quartoblog",
    "section": "",
    "text": "The purpose of this notebook is to collect all the finger exercises I did from Introduction to Computation and Programming Using Python, third edition, With Application to Computational Modeling and Understanding Data by John V. Guttag.\n(Btw it is not complete, I didn’t do for example some very basic finger exercises toward the beginning of the book.)"
  },
  {
    "objectID": "posts/finger_exercises.html#chapter-3-some-simple-numerical-programs",
    "href": "posts/finger_exercises.html#chapter-3-some-simple-numerical-programs",
    "title": "quartoblog",
    "section": "Chapter 3: Some Simple Numerical Programs",
    "text": "Chapter 3: Some Simple Numerical Programs\n\n3.1 Exhaustive Enumeration\nWrite a program that asks the user to enter an integer and prints two integers, root and pwr, such that 1 &lt; pwr &lt; 6 and root**pwr is equal to the integer entered by the user. If no such pair of integers exists, it should print a message to that effect.\n\nx = int(input(\"Enter an integer: \"))\nanswer_root, answer_pwr = None, None\nif x == 0:\n    answer_root, answer_pwr = 0, 2\nelse:\n    if x &lt; 0:\n        for pwr in range(3, 6, 2):\n            for root in range(abs(x) + 1):\n                root *= -1\n                if root**pwr == x:\n                    answer_root, answer_pwr = root, pwr\n                    break\n    else:\n        for pwr in range(2, 6):\n            for root in range(abs(x) + 1):\n                if root**pwr == x:\n                    answer_root, answer_pwr = root, pwr\n                    break\nif answer_root is not None:\n    print(f\"For {x}, root is {answer_root} and power is {answer_pwr}\")\nelse:\n    print(\"No such pair exists.\")\n\nFor -8, root is -2 and power is 3\n\n\nWrite a program that prints the sum of the prime numbers greater than 2 and less than 1000. Hint: you probably want to have a loop that is a primality test nested inside a loop that iterates over the odd integers between 3 and 999.\n\nx = 0\nfor i in range(3, 1000, 2):\n    is_prime = True\n    for j in range(2, i):\n        if i % j == 0:\n            is_prime = False\n            break\n    if is_prime:\n        x += i\nprint(x)\n\n76125\n\n\n\n\n3.2 Approximate Solutions and Bisection Search\nWhat would have to be changed to make the code in Figure 3-5 work for finding an approximation to the cube root of both negative and positive numbers? Hint: think about changing low to ensure that the answer lies within the region being searched.\n\nx = float(input(\"Enter a number: \"))\nepsilon = 0.01\nlow = min(x, -1)\nhigh = max(1, x)\nans = (high + low) / 2\nnum_guesses = 1\nprint(f\"{low = }, {high = }, {ans = }\")\nwhile abs(ans**3 - x) &gt;= epsilon:\n    num_guesses += 1\n    if ans**3 &lt; x:\n        low = ans\n    else:\n        high = ans\n    ans = (high + low) / 2\n    print(f\"{low = }, {high = }, {ans = }\")\nprint(f\"{num_guesses = }\")\nprint(ans, \"is close to cube root of\", x)\n\nlow = -27.0, high = 1, ans = -13.0\nlow = -13.0, high = 1, ans = -6.0\nlow = -6.0, high = 1, ans = -2.5\nlow = -6.0, high = -2.5, ans = -4.25\nlow = -4.25, high = -2.5, ans = -3.375\nlow = -3.375, high = -2.5, ans = -2.9375\nlow = -3.375, high = -2.9375, ans = -3.15625\nlow = -3.15625, high = -2.9375, ans = -3.046875\nlow = -3.046875, high = -2.9375, ans = -2.9921875\nlow = -3.046875, high = -2.9921875, ans = -3.01953125\nlow = -3.01953125, high = -2.9921875, ans = -3.005859375\nlow = -3.005859375, high = -2.9921875, ans = -2.9990234375\nlow = -3.005859375, high = -2.9990234375, ans = -3.00244140625\nlow = -3.00244140625, high = -2.9990234375, ans = -3.000732421875\nlow = -3.000732421875, high = -2.9990234375, ans = -2.9998779296875\nnum_guesses = 15\n-2.9998779296875 is close to cube root of -27.0\n\n\nFigure 3-6 Using bisection search to estimate log base 2. (This is not a finger exercise, but I thought Figure 3-6 was wrong in that it doesn’t work for 0 &lt; x &lt; 1 and it is inefficient for huge x, so I wanted to improve on it. - I was right about 0 &lt; x &lt; 1, but it turned out for huge x it was actually efficient. It is because 2**ans very quickly reaches overflow error, so we should be very careful about low and high to ensure they are as tight as possible to prevent the overflow error.)\n\ny = float(input(\"Enter a positive number: \"))\nepsilon = 0.01\nlower_bound = 0\nif y &lt; 1:\n    x = 1 / y\nelse:\n    x = y\nwhile 2**lower_bound &lt; x:\n    lower_bound += 1\nlow = lower_bound - 1\nhigh = lower_bound + 1\nans = (high + low) / 2\nprint(f\"{low = }, {high = }, {ans = }\")\nwhile abs(2**ans - x) &gt;= epsilon:\n    if 2**ans &lt; x:\n        low = ans\n    else:\n        high = ans\n    ans = (high + low) / 2\n    print(f\"{low = }, {high = }, {ans = }\")\nif y &lt; 1:\n    print(-ans, \"is close to the log base 2 of\", y)\nelse:\n    print(ans, \"is close to the log base 2 of\", y)\n\nlow = 2, high = 4, ans = 3.0\n-3.0 is close to the log base 2 of 0.125\n\n\n\n\n3.4 Newton-Raphson\nAdd some code to the implementation of Newton-Raphson (in Figure 3-7) that keeps track of the number of iterations used to find the root. Use that code as part of a program that compares the efficiency of Newton-Raphson and bisection search. (You should discover that Newton-Raphson is far more efficient). Note: I also changed the code to find the cube root.\n\nk = float(input(\"Enter a number: \"))\nepsilon = 0.01\nguess = k / 2\nnum_guesses = 1\nwhile abs(guess**3 - k) &gt;= epsilon:\n    num_guesses += 1\n    guess -= (guess**3 - k) / (3 * guess**2)\nprint(f\"{num_guesses = }\")\nprint(\"Cube root of\", k, \"is about\", guess)\n\nnum_guesses = 8\nCube root of -27.0 is about -3.000000081210202"
  },
  {
    "objectID": "posts/finger_exercises.html#chapter-4-functions-scoping-and-abstraction",
    "href": "posts/finger_exercises.html#chapter-4-functions-scoping-and-abstraction",
    "title": "quartoblog",
    "section": "Chapter 4: Functions, Scoping, and Abstraction",
    "text": "Chapter 4: Functions, Scoping, and Abstraction\nUse find to implement a function satisfying the specifiaction\n\ndef find_last(s, sub):\n    \"\"\"s and sub are non-empty strings\n    Returns the index of the last occurence of sub in s.\n    Returns None if sub does not occur in s\"\"\"\n    if s.find(sub) == -1:\n        return None\n    else:\n        return len(s) - len(sub) - s[::-1].find(sub[::-1])"
  },
  {
    "objectID": "posts/finger_exercises.html#chapter-5-structured-types-and-mutability",
    "href": "posts/finger_exercises.html#chapter-5-structured-types-and-mutability",
    "title": "quartoblog",
    "section": "Chapter 5: Structured Types and Mutability",
    "text": "Chapter 5: Structured Types and Mutability\nUsing encoder and encrypt as models, implement the functions decoder and decrypt. Use them to decrypt the message\n\nbook = \"In a village of La Mancha, the name of which I have no desire to call to mind, there lived not long since one of those gentlemen that keep a lance in the lance-rack, an old buckler, a lean hack, and a greyhound for coursing.\"\ncipher_text = \"22*13*33*137*59*11*23*11*1*57*6*13*1*2*6*57*2*6*1*22*13*33*137*59*11*23*11*1*57*6*173*7*11\"\n\n\ngen_decode_keys = lambda book, cipher_text: {\n    s: book[int(s)] for s in set(cipher_text.split(\"*\"))\n}\n\n\ndecoder = lambda decode_keys, cipher_text: \"\".join(\n    [decode_keys[s] for s in cipher_text.split(\"*\")]\n)\n\n\ndecrypt = lambda book, cipher_text: decoder(\n    gen_decode_keys(book, cipher_text), cipher_text\n)\n\n\ndecrypt(book, cipher_text)\n\n'comprehension is incomprehensible'\n\n\nNote: We could decipher the text without creating the decrypt function using the call decoder(gen_decode_keys(book, cipher_text), cipher_text). I mean, we have eveything we need to decrypt the message before we implement the decrypt function. I guess the function decrypt is created for convenience, so that to decipher a message, we have a function with a straightforward usage: One parameter is the book and one parameter is the cipher text and we don’t have to care about anything else. I think that is to honor the abstraction. We shouldn’t care about how the function works (i.e. that it uses decoder and gen_decode_keys functions) as long as it simply takes the book, the cipher text and produces the decoded the message."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quartoblog",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "posts/Floating-Point.html",
    "href": "posts/Floating-Point.html",
    "title": "quartoblog",
    "section": "",
    "text": "This is a topic that breaks my head each time I try to understand it. This is a summary of what I know and what I don’t."
  },
  {
    "objectID": "posts/Floating-Point.html#purpose",
    "href": "posts/Floating-Point.html#purpose",
    "title": "quartoblog",
    "section": "Purpose",
    "text": "Purpose\nFloating point is a way to represent scientific notation in a computer. Its purpose is to be able to represent both values that are very very small and values that are very very big."
  },
  {
    "objectID": "posts/Floating-Point.html#internal-representation",
    "href": "posts/Floating-Point.html#internal-representation",
    "title": "quartoblog",
    "section": "Internal representation",
    "text": "Internal representation\nInternal representation is a tripplet of sign, exponent and a significand (also called fraction or mantissa, represents the significant digits). On most current computers, the used standard is called IEEE 754. Its double-precision format, “binary64”, has 1 bit for the sign, 11 bits for the exponent and 53 bits for the significand."
  },
  {
    "objectID": "posts/Floating-Point.html#normalization",
    "href": "posts/Floating-Point.html#normalization",
    "title": "quartoblog",
    "section": "Normalization",
    "text": "Normalization\nSince there are possibly many ways to decompose a number into such triplet (for example, the number 12 can be represented by either \\(12 \\times 2^0\\), \\(3 \\times 2^2\\) or \\(1.5 \\times 2^3\\)), the numbers are stored in a normalized form. That means that the significand represents digits after a decimal point after a \\(1\\). So each floating point number is represented as \\((-1)^{sign} \\times 1.fraction \\times 2^{exponent}\\). The purpose of this normalization is to maximize efficiency and precision."
  },
  {
    "objectID": "posts/Floating-Point.html#not-every-number-is-representable",
    "href": "posts/Floating-Point.html#not-every-number-is-representable",
    "title": "quartoblog",
    "section": "Not every number is representable",
    "text": "Not every number is representable\nSince the significand has a finite number of bits available, some numbers are simply not representable. Famously, the number \\(0.1\\) is not perfectly representable, because in base 2 one would need infinite digits of the significand to represent it perfectly. It is similar to the number \\(\\frac{1}{3}\\) not being perfectly representable in base 10 with finite number of significant digits. For example, with 5 significant (decimal) digits, the best you could do is to represent \\(\\frac{1}{3}\\) by \\(0.33333\\)."
  },
  {
    "objectID": "posts/Floating-Point.html#rounding",
    "href": "posts/Floating-Point.html#rounding",
    "title": "quartoblog",
    "section": "Rounding",
    "text": "Rounding\nWhen this happens (the number entered is not perfectly representable), the floating point standard performs rounding. It represents the entered number as a close representable number. The direction of rounding can be either toward zero, to the nearest representable number, toward positive infinity or toward negative infinity. So, the code 0.1 + 0.1 + 0.1 == 0.3 evaluates to False, because the addition on the left-hand side is rounded to a different number than what the number 0.3 is represented with.\n\nprint(f\"{0.1+0.1+0.1:.60f}\")\n\nprint(f\"{0.3:.60f}\")\n\n0.300000000000000044408920985006261616945266723632812500000000\n0.299999999999999988897769753748434595763683319091796875000000"
  },
  {
    "objectID": "posts/Floating-Point.html#sys.float_info",
    "href": "posts/Floating-Point.html#sys.float_info",
    "title": "quartoblog",
    "section": "sys.float_info",
    "text": "sys.float_info\nIn Python, the parameters of floating point arithmetics on a particular machine can be found using the attribute float_info of the module sys. See the docs. For example, we can see that the rounding mode on my computer is “toward nearest”.\n\nimport sys\n\nprint(sys.float_info)\n\nsys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n\n\nNotice the value dig, “the maximum number of decimal digits that can be faithfully represented in a float”. To me, it is surprisingly small. On my computer, any number that has 15 or less significant digits, can be converted from str to float and back without change of value. But numbers with more than 15 significant digits aren’t guarranteed to have this property:\n\ns = \"3.14159265358979\"\nprint(s)\nprint(f\"{float(s):.60}\")\nprint(str(float(s)))\nprint(\"----------\")\ns = \"0.000000314159265358979\"\nprint(s)\nprint(f\"{float(s):.60}\")\nprint(str(float(s)))\n\n3.14159265358979\n3.141592653589790007373494518105871975421905517578125\n3.14159265358979\n----------\n0.000000314159265358979\n3.14159265358979004489366594968235979479231900768354535102844e-07\n3.14159265358979e-07\n\n\n\ns = \"9.876543210123459\"\nprint(s)\nprint(f\"{float(s):.60}\")\nprint(str(float(s)))\n\n9.876543210123459\n9.8765432101234598150085730594582855701446533203125\n9.87654321012346"
  },
  {
    "objectID": "posts/Floating-Point.html#accumulation-of-rounding-error",
    "href": "posts/Floating-Point.html#accumulation-of-rounding-error",
    "title": "quartoblog",
    "section": "Accumulation of rounding error",
    "text": "Accumulation of rounding error\nLet’s look at this code:\n\nx = 0\nfor _ in range(10):\n    x += 0.1\n    print(f\"{x:.55f}\")\n\n0.1000000000000000055511151231257827021181583404541015625\n0.2000000000000000111022302462515654042363166809082031250\n0.3000000000000000444089209850062616169452667236328125000\n0.4000000000000000222044604925031308084726333618164062500\n0.5000000000000000000000000000000000000000000000000000000\n0.5999999999999999777955395074968691915273666381835937500\n0.6999999999999999555910790149937383830547332763671875000\n0.7999999999999999333866185224906075745820999145507812500\n0.8999999999999999111821580299874767661094665527343750000\n0.9999999999999998889776975374843459576368331909179687500\n\n\nThe rounding errors are sometimes positive, sometimes negative. All in all, I think they are basicaly random. But they can accumulate over a large amount of operations. This code should test this.\nTo explain this code: It is obviously impossible to measure the rounding error of numbers that aren’t perfectly representable, like 0.1. Because I can’t represent the actual value to compare the floating point number with. But integers up to 10^sys.float_info[max_10_exp] are perfectly representable. I’m using this fact and measuring the rounding error after each 10th iteration.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nw, x, y, z = 0, 0, 0, 0\nerrors_1, errors_3, errors_7, errors_9 = [], [], [], []\nfor i in range(1, 1_000_001):\n    w += 0.1\n    x += 0.3\n    y += 0.7\n    z += 0.9\n    if i != 1 and i % 10 == 0:\n        errors_1.append(w - i * 0.1)\n        errors_3.append(x - i * 0.3)\n        errors_7.append(y - i * 0.7)\n        errors_9.append(z - i * 0.9)\n\n\nplt.plot(errors_1)\nplt.plot(errors_3)\nplt.plot(errors_7)\nplt.plot(errors_9)\n\n\n\n\n\n\n\n\n\nplt.plot(np.log10(np.abs(np.array(errors_1))))\nplt.plot(np.log10(np.abs(np.array(errors_3))))\nplt.plot(np.log10(np.abs(np.array(errors_7))))\nplt.plot(np.log10(np.abs(np.array(errors_9))))\n\nC:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7900\\2778079877.py:1: RuntimeWarning: divide by zero encountered in log10\n  plt.plot(np.log10(np.abs(np.array(errors_1))))\nC:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7900\\2778079877.py:2: RuntimeWarning: divide by zero encountered in log10\n  plt.plot(np.log10(np.abs(np.array(errors_3))))\nC:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7900\\2778079877.py:3: RuntimeWarning: divide by zero encountered in log10\n  plt.plot(np.log10(np.abs(np.array(errors_7))))\nC:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_7900\\2778079877.py:4: RuntimeWarning: divide by zero encountered in log10\n  plt.plot(np.log10(np.abs(np.array(errors_9))))\n\n\n\n\n\n\n\n\n\nWe can see the the magnitude of the error always fluctuates around zero, and sometimes is exactly zero (hence the errors RuntimeWarning: divide by zero encountered in log10), but the magnitude of this fluctuation generally increases with increasing number of floating point operations.\nHowever, the situation is a bit different when applied to subtracting. The errors are always in the same direction and their increase in magnitude is a bit questionable. So I’m actually confused.\n\nnum_iters = 1_000_000\nw, x, y, z = (\n    int(num_iters * 0.1),\n    int(num_iters * 0.3),\n    int(num_iters * 0.7),\n    int(num_iters * 0.9),\n)\nerrors_1, errors_3, errors_7, errors_9 = [], [], [], []\nfor i in range(1, num_iters + 1):\n    w -= 0.1\n    x -= 0.3\n    y -= 0.7\n    z -= 0.9\n    if i != 1 and i % 10 == 0:\n        errors_1.append(w - (int(num_iters * 0.1) - i * 0.1))\n        errors_3.append(x - (int(num_iters * 0.3) - i * 0.3))\n        errors_7.append(y - (int(num_iters * 0.7) - i * 0.7))\n        errors_9.append(z - (int(num_iters * 0.9) - i * 0.9))\n\n\nplt.plot(errors_1)\nplt.plot(errors_3)\nplt.plot(errors_7)\nplt.plot(errors_9)\n\n\n\n\n\n\n\n\n\nplt.plot(np.log10(np.abs(np.array(errors_1))))\nplt.plot(np.log10(np.abs(np.array(errors_3))))\nplt.plot(np.log10(np.abs(np.array(errors_7))))\nplt.plot(np.log10(np.abs(np.array(errors_9))))"
  }
]